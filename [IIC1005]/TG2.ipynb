{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbbce8db",
   "metadata": {},
   "source": [
    "# Tarea Grande 2\n",
    "Integrantes: Andrés Cabezas y Nicolás Olate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9472b0",
   "metadata": {},
   "source": [
    "## Parte 1: Procesamiento de los datos\n",
    "### Importar librerías\n",
    "En este paso se van a importar las librerías que se van a usar durante la tarea. Estas son Pandas, Matplotlib, Seaborn y scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db6219c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12068/605399801.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Importando librerías de scikit-learn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd #Importando librería Pandas\n",
    "import matplotlib.pyplot as plt #Importando librería Matplotlib\n",
    "import seaborn as sns #Importando librería Seaborn\n",
    "\n",
    "#Importando librerías de scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54634a70",
   "metadata": {},
   "source": [
    "\n",
    "<br> <br>\n",
    "### Carga de datos \n",
    "<br>\n",
    "En esta parte se debe importar el set de datos en formato .csv que se ha proporcionado para la tarea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b16574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1663.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>169.0</td>\n",
       "      <td>...</td>\n",
       "      <td>831.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1663.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>147.0</td>\n",
       "      <td>...</td>\n",
       "      <td>951.0</td>\n",
       "      <td>1545.0</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1323.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>131.0</td>\n",
       "      <td>...</td>\n",
       "      <td>162.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>146.0</td>\n",
       "      <td>...</td>\n",
       "      <td>393.0</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>1699.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1563.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>410.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>2195</td>\n",
       "      <td>1867.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>191.0</td>\n",
       "      <td>...</td>\n",
       "      <td>712.0</td>\n",
       "      <td>1442.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>2196</td>\n",
       "      <td>541.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1226.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>2197</td>\n",
       "      <td>1814.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>141.0</td>\n",
       "      <td>...</td>\n",
       "      <td>756.0</td>\n",
       "      <td>786.0</td>\n",
       "      <td>3556.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>2198</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>152.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>1732.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>2199</td>\n",
       "      <td>987.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>419.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>2757.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2200 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  battery_power  blue  clock_speed  dual_sim    fc  four_g  \\\n",
       "0              0         1663.0   1.0          2.5       1.0  13.0     1.0   \n",
       "1              1         1663.0   1.0          0.5       0.0   0.0     0.0   \n",
       "2              2         1323.0   1.0          2.5       1.0  10.0     1.0   \n",
       "3              3         1099.0   0.0          0.5       0.0  13.0     1.0   \n",
       "4              4         1563.0   0.0          1.7       1.0  10.0     0.0   \n",
       "...          ...            ...   ...          ...       ...   ...     ...   \n",
       "2195        2195         1867.0   0.0          2.3       0.0   0.0     1.0   \n",
       "2196        2196          541.0   1.0          2.3       0.0   4.0     0.0   \n",
       "2197        2197         1814.0   0.0          1.4       1.0   1.0     1.0   \n",
       "2198        2198         1027.0   1.0          2.2       0.0   0.0     0.0   \n",
       "2199        2199          987.0   1.0          1.9       0.0   4.0     1.0   \n",
       "\n",
       "      int_memory  m_dep  mobile_wt  ...  px_height  px_width     ram  sc_h  \\\n",
       "0           27.0    0.3      169.0  ...      831.0    1439.0  2084.0   7.0   \n",
       "1           40.0    0.6      147.0  ...      951.0    1545.0  1336.0   8.0   \n",
       "2           28.0    0.2      131.0  ...      162.0     619.0  1892.0  10.0   \n",
       "3           61.0    0.3      146.0  ...      393.0    1096.0  1699.0  17.0   \n",
       "4           16.0    0.1      151.0  ...      410.0     572.0  3922.0  11.0   \n",
       "...          ...    ...        ...  ...        ...       ...     ...   ...   \n",
       "2195         9.0    0.1      191.0  ...      712.0    1442.0   990.0   6.0   \n",
       "2196        51.0    0.4      200.0  ...     1012.0    1226.0   403.0  11.0   \n",
       "2197         9.0    0.4      141.0  ...      756.0     786.0  3556.0  18.0   \n",
       "2198        63.0    0.8      102.0  ...      152.0     714.0  1732.0   8.0   \n",
       "2199        52.0    0.5       83.0  ...      419.0     736.0  2757.0  17.0   \n",
       "\n",
       "      sc_w  talk_time  three_g  touch_screen  wifi  price_range  \n",
       "0      1.0       18.0      1.0           0.0   0.0          2.0  \n",
       "1      5.0       15.0      1.0           0.0   0.0          1.0  \n",
       "2      0.0       15.0      1.0           1.0   1.0          1.0  \n",
       "3     10.0        3.0      1.0           1.0   1.0          1.0  \n",
       "4      1.0        8.0      0.0           0.0   1.0          3.0  \n",
       "...    ...        ...      ...           ...   ...          ...  \n",
       "2195   1.0        2.0      1.0           0.0   1.0          1.0  \n",
       "2196   2.0       12.0      0.0           0.0   0.0          0.0  \n",
       "2197  12.0       16.0      1.0           0.0   0.0          3.0  \n",
       "2198   5.0       13.0      0.0           1.0   1.0          1.0  \n",
       "2199  12.0       15.0      1.0           1.0   0.0          2.0  \n",
       "\n",
       "[2200 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('celulares.csv', sep = ',') #Se carga el archivo celulares.csv utilizando Pandas\n",
    "df #Se muestra el dataframe de Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc47b074",
   "metadata": {},
   "source": [
    "\n",
    "<br><br>\n",
    "### Reconocimiento de información  y análisis de características\n",
    "<br>\n",
    "Ahora se va a hacer un análisis previo de nuestro dataset para poder ver con qué estamos trabajando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6193c3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2200, 22)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape) #Este comando imprime el tamaño de nuestro dataframe\n",
    "#(Filas y columnas respectivamente)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9189133",
   "metadata": {},
   "source": [
    "Podemos ver que nuestro dataframe tiene 2200 filas (correspondientes a modelos de celulares), y 22 columnas (correspondientes a los distintos atributos o columnas que se están analizando de cada modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e692e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist()) #Imprime una lista con los titulos de todas las columnas del DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791d8a87",
   "metadata": {},
   "source": [
    "La lista que nos entrega este comando corresponde a cada uno de los atributos que estamos analizando en nuestro dataset, esto se hace mediante la funcion .columns.tolist el cual convierte los nombres de las columnas en una lista. Así podemos visualizar de manera correcta las columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e6e525",
   "metadata": {},
   "source": [
    "- El objetivo de este trabajo es realizar un análisis de un set de datos de celulares, este análisis será bajo la predicción de ciertos modelos. En primer lugar se intentará predecir una clasificación automática de los celulares, entrenando y posteriormente evaluando cierto algoritmo según la etiqueta de rango de precios (price_range). Además, se busca predecir bajo un modelo de regresión los datos bajo la etiqueta de la memoria interna (int_memory). <br>\n",
    "- Para cumplir nuestro objetivo, vamos a elegir que caractéristicas cumplen o son efiecientes a la hora de generar esta clasificación y regresión automática.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d110d3d6",
   "metadata": {},
   "source": [
    "##### Gráficos\n",
    "Ahora vamos a proceder a crear gráficos que nos permitan conocer algunas cosas de nuestro dataset, en conjunto con lograr estudiarlo y comprender a fondo los datos que lo componen. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45622aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genera un gráfico de puntos, el cual nos muestre la distribución de los datos según las etiquetas 'pc' y 'price_range'\n",
    "sns.swarmplot(data = df, x = 'price_range', y = 'pc', size = 2).set_title('Precio / Calidad de Cámara')\n",
    "#sns.swarmplot: Comando que usa las librerías de Seaborn para generar un gráfico del tipo swarmplot\n",
    "#data = df: Se asigna el dataframe df como datos para generar el gráfico\n",
    "#x = 'price_range': Se asigna la columna 'price_range' del dataframe como el eje X\n",
    "#y = 'pc': Se asigna la columna 'pc' del dataframe como el eje Y\n",
    "#size = 2: Se modifica el tamaño de los puntos que forman el gráfico, para que el gráfico se pueda mostrar de forma correcta. (Default: size = 5)\n",
    "#set_title: Recibe un string como argumento, para ponerle un título al gráfico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8ca99f",
   "metadata": {},
   "source": [
    "En este gráfico, en el eje X colocamos los rangos de precios, y en el eje Y colocamos la calidad de la cámara primaria del celular, intentando buscar una relación entre el precio y la calidad de la cámara que uno recibe. Al ver este gráfico, podemos notar que el rango de precio, no tiene influencia alguna en la calidad que tiene la cámara principal, aunque podemos notar que al fijarnos en algun rango de la calidad de la cámara en especifico, se puede ver que existe dentro de ese rango un aumento en la frecuencia dentro de esos rangos de precios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genera un gráfico de caja y bigotes\n",
    "sns.boxplot(data = df, x = 'n_cores', y = 'int_memory').set_title('Gráfico de caja y bigotes de memoria interna para cada cantidad de nucleos')\n",
    "#sns.boxplot: Comando que usa las librerías de Seaborn para generar un gráfico del tipo boxplot\n",
    "#data = df: Asigna el dataframe df como datos para generar el gráfico\n",
    "#x = 'price_range': Asigna la columna 'n_cores' del dataframe como el eje X\n",
    "#y = 'int_memory': Asigna la columna 'int_memory' del dataframe como el eje Y\n",
    "#set_title: Recibe un string como argumento, para ponerle un título al gráfico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3dd5aa",
   "metadata": {},
   "source": [
    "En este gráfico de caja y bigotes, podemos ver la relación entre la cantidad de nucleos en el procesador de un celular y la cantidad de memoria interna. Se puede ver que todo se encuentra bien distribuido, y que casi todos los grupos de nucleos tienen una memoria interna media muy similar, lo que sugiere que la cantidad de nucleos no afecta realmente a la memoria interna que posee el dispositivo, otra vez más mostrandonos la independencia entre las características del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280e7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genera un gráfico de puntos con tonos de colores que distinguen una característica en particular\n",
    "sns.relplot(data = df, x = 'sc_w', y = 'sc_h', hue = 'touch_screen', palette = 'vlag')\n",
    "#sns.relplot: Comando que usa las librerías de Seaborn para generar un gráfico del tipo relplot\n",
    "#data = df: Se asigna el dataframe df como datos para generar el gráfico\n",
    "#x = 'sc_w': Se asigna la columna 'sc_w' como el eje X\n",
    "#y = 'sc_h': Se asigna la columna 'sc_h' como el eje Y\n",
    "#hue = 'touch_screen': Se asigna la columna 'touch_screen' como dato discriminador, que cambiará los colores que tiene el gráfico\n",
    "#palette = vlag: Se asigna la paleta de colores 'vlag' para el gráfico. Esto cambia los colores que se usan para el hue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b63a5c",
   "metadata": {},
   "source": [
    "En este gráfico colocamos en el eje X, el ancho de la pantalla del celular, y en el eje Y la altura de la pantalla. El color de los puntos indica la presencia o ausencia de una pantalla touch. Podemos ver que el tamaño de la pantalla no tiene relación con el hecho de ser tactil o no, pero podemos observar también de que hay ciertos tamaños que no existen. Más especificamente: No existen teléfonos que sean muy anchos, pero si existen telefonos que son de proporciones más altas. Si bien existen relaciones físicas, podemos notar que una y otra vez los datos siguen una independencia entre las características lo que hace óptimo usar un modelo de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa35f1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Grafico de cantidad de nucleos respecto al precio\n",
    "sns.catplot(data = df, x = 'n_cores', hue = 'price_range', kind = 'count')\n",
    "#sns.catplot: Comando que usa la librería Seaborn para generar un grafico catplot\n",
    "#data = df: Se entrega df como datos para el gráfico\n",
    "#x = 'n_cores': Se asigna la columna n_cores como eje X del gráfico\n",
    "#hue = 'price_range': Se asigna la columna price_range como dato para comparar (hue se encarga de eso)\n",
    "#kind = 'count': Esto hace que el gráfico determine frecuencia del dato del eje X para colocarlo en el eje Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95638669",
   "metadata": {},
   "source": [
    "En este gráfico podemos notar que la cantidad de núcleos en el procesador de un celular y el rango de precio que tienen los celulares, no parecieran tener relación alguna, ya que ningun rango de precio pareciera ser consistente con la cantidad de nucleos. <br>\n",
    "Por ejemplo, no pareciera ser que consistentemente los telefonos con menos nucleos pertenezcan a rangos de precios más bajos o altos. Los que tienen 1 nucleo, son predominantemente del rango de precio 1, los de 2 nucleos son predominantemente del rango de precio 0, los de 3 nucleos son predominantemente del rango de precio 1, y así."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aa0d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico de RAM respecto al precio\n",
    "sns.boxplot(data = df, x = 'price_range', y = 'ram')\n",
    "#sns.boxplot: Comando que usa las librerías de Seaborn para generar un gráfico del tipo boxplot\n",
    "#data = df: Asigna el dataframe df como datos para generar el gráfico\n",
    "#x = 'price_range': Asigna la columna 'price_range' del dataframe como el eje X\n",
    "#y = 'ram': Asigna la columna 'ram' del dataframe como el eje Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db45630",
   "metadata": {},
   "source": [
    "En este gráfico podemos ver como se distribuye la cantidad de RAM que tienen distintos telefonos con un rango de precio en común. Usamos el gráfico de Caja y Bigotes, debido a que este es capaz de mostrar de manera eficiente como se tienden a agrupar ciertos datos. Aqui podemos ver como a medida que el rango de precio aumenta, la cantidad de RAM más común aumenta tambien, lo que indica que el rango de precios y la RAM tienen una relación fuerte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a3e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico de talk time respecto a precio\n",
    "sns.boxplot(data = df, x = 'price_range', y = 'talk_time')\n",
    "#sns.boxplot: Comando que usa las librerías de Seaborn para generar un gráfico del tipo boxplot\n",
    "#data = df: Asigna el dataframe df como datos para generar el gráfico\n",
    "#x = 'price_range': Asigna la columna 'price_range' como eje X del gráfico\n",
    "#y = 'talk_time': Asigna la columna 'talk_time' como eje Y del gráfico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468d4374",
   "metadata": {},
   "source": [
    "En este gráfico se intenta relacionar la duración de la batería (cuanto dura la batería mientras se habla por telefono). Para poder visualizarlo correctamente, decidimos usarel gráfico de Caja y Bigotes nuevamente, sin embargo, no se logro encontrar una relación consistente, ya que la media de la duración de la batería se mantiene casi constante, y no aumenta o disminuye de manera signficativa entre rangos de precio, y tampoco varía de una forma consistente. Con respecto a eso ultimo, se puede ver que al cambiar de 0 a 1, el promedio de duracion de la bateria sube, pero al pasar de 1 a 2, baja."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15493bc8",
   "metadata": {},
   "source": [
    "Tomamos la decisión de solamente quitar entre los atributos a considerar, la columna 'Unnamed: 0'. Decidimos quitar la columna Unnamed, debido a que esta parecía ser solamente un ID del teléfono en especifico del que estamos hablando, sin embargo, Pandas asigna ya un ID el cual coincide con el número presente en esa columna, por lo cual no aporta ninguna información, además de que no es una cualidad o característica del dispositivo en sí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b500125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'],axis = 1) #Quitar columna de \"Unnamed:0\" del DataFrame df = df.drop([],axis = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4843f7c",
   "metadata": {},
   "source": [
    ">Este comando se hizo con la ayuda de la documentación de Pandas. Este elimina las columnas especificando los nombres de las etiquetas y el eje correspondiente.<br>\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35098f5",
   "metadata": {},
   "source": [
    "A pesar de los resultados que tenemos en nuestros gráficos, tomamos la decisión de no quitar ningún parámetro, aparte del ID de cada dispositivo (Columna 'Unnamed 0'). El motivo es que, considerando que tenemos pocos datos a nuestra disposición (considerando que para este tipo de tareas, en muchas ocasiones se trabaja con datasets más grandes que este), consideramos que para entrenar de mejor manera a nuestro clasificador y a nuestro regresor, es mejor dejarle más cosas para trabajar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0611d50c",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### Limpieza de los datos <br>\n",
    "Ahora lo que vamos a hacer es buscar en el dataset si tenemos valores nulos o NaN, para poder limpiarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f77e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna() #Eliminar todos los datos que tengan NaN en el DataFrame, esto gracias a la función .dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0942ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().values.any() #Verificar si hay valores NaN en el dataframe, esto al entregar la función isnull().values.any() nos entrega un booleano el cual nos dice si existen datos Nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4eee93",
   "metadata": {},
   "source": [
    ">El codigo que se escribió se hizo con ayuda del siguiente recurso en linea: <br>\n",
    "https://datatofish.com/dropna/\n",
    "\n",
    "Tomamos la decisión de deshacernos de todo teléfono que en alguna parte tuviera datos NaN. Esto lo hicimos debido a que no tenemos una información que esté completa, y otras formas de deshacerse de los NaN, como por ejemplo, reemplazarlos por ceros, contaminarian un poco el dataset que estamos usando, generando posible información erronea (Ej.: Un teléfono con un procesador de 0 nucleos no hace sentido). Por lo tanto, consideramos que es mejor simplemente no considerar el teléfono del cual no tenemos información completa. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9461e0d0",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### Separando la clase y normalizando\n",
    "En esta parte se separará el dataset en la matriz característica y el vector de clases. El vector de clase corresponderá al rango de precios (price_range) y el regresor será la memoria interna (int_memory). <br>\n",
    "Además nos damos cuenta que en múltiples características los datos tienen distintos rangos, por ejemplo en \"battery_power\", \"clock_speed\", etc. Esto hace necesaria la labor de normalizar ya que una diferencia entre nucleos puede parecer mínima frente a la RAM, cosa que es completamente al reves. Es por esto que es necesario normalizar los datos para así poder distribuirlos normalmente y tener bajo un mismo estándar las proporciones de distancias entre datos de una misma característica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b83d05d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df #Al mostrar el dataset podemos notar que en múltiples caracterícas los rangos de valores y de diferencia son muy distintos entre ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b34aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, :20].values #x es una matriz que incluye todas las características\n",
    "y = df.iloc[: ,20].values #y es el vector de clases \n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b4b07",
   "metadata": {},
   "source": [
    "A través de estos comandos, se crearon la matriz de características (x) y el vector de clases (y). <br>\n",
    "La creación de ambas cosas fue gracias al comando iloc[ ].values. La matriz de características contiene todas las columnas de características a excepción del vector de clases que en este caso es el rango de precios. Por otro lado, el vector de clases es un vector que corresponde al rango de los precios (price_range)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faff6cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "col=['battery_power','blue','clock_speed','dual_sim','fc','four_g','m_dep','mobile_wt','n_cores','pc','px_height','px_width','ram','sc_h','sc_w','talk_time','three_g','touch_screen','wifi','price_range']\n",
    "X= df[col].values      #X es una matriz que incluye todas las características\n",
    "Y= df.iloc[:,6].values #Y es el vector de regresión (int_memory) \n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8859b8b0",
   "metadata": {},
   "source": [
    "Luego se encuentra el regresor con su matriz de características. Para esto, elegimos las características que deben incorporarse a esta matriz eligiendo las columnas y almacenandolas en la variable col. Finalmente, creamos la matriz X agregando las columnas almacenadas anteriormente.<br>\n",
    "Tras esto, creamos el regresor que consiste en un vector de clase que tiene como característica a la memoria interna (int_memory). Mediante el comando iloc[ ] seleccionamos la columna a transformar en el vector. <br> \n",
    "Con el comando .shape percibimos la cantidad de filas y columnas que tenga la matriz, en este caso 2000 filas y 20 columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daee648",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = MinMaxScaler().fit_transform(x) #Se usa MinMaxScaler() para normalizar con el método MinMax\n",
    "X = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cf3cb3",
   "metadata": {},
   "source": [
    "Luego de obtener la matriz de características y el vector de clase, pasamos a normalizar los datos. Esto se hace con el fin de preparar nuestros datos, haciendo que todas las columnas con datos numéricos usen una escala en común sin alterar las diferencias en los rangos de valores y sin perder información.<br>\n",
    "\n",
    ">https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/normalize-data <br>\n",
    "\n",
    "Para normalizar usamos el método MinMaxScaler, este comando tiene como función restar el valor dado con su mínimo, dividiéndolo con el rango de la muestra. Esto realiza para todos los puntos. Luego el \"fit_transform\" 'fitea' para la matriz que buscamos normalizar. <br>\n",
    "Elegimos este método de normalización ya que es capaz de preservar los rangos y proporciones numéricas de los datos, manteniendo una escala común para todas las columnas (entre 0 y 1), lo que hace efectivo a la hora de entrenar o clasificar algún modelo. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7816d2",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Parte 2: Clasificación automática y regresión\n",
    "### Separando los datos de entrenamiento y pruebas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99af5511",
   "metadata": {},
   "source": [
    "Para terminar de preparar los datos para el entrenamiento, debemos dividir el set en que porcentaje de los datos se usarán para el testeo y cuanto para el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e2817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15) #Se estan preparando los datos para practicar y probar la clasificación \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15) #Se estan preparando los datos para practicar y probar la regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5452207",
   "metadata": {},
   "source": [
    "En primer lugar, lo que hace estos comandos es almacenar en una serie de variables, que almacenarán por porciones el data. El train_test_split requiere de dos parámetros que, que agregando la porción que el usuario necesite se asignaran aleatoriamente los datos. <br> <br>\n",
    "Decidimos que la proporción entre los datos de entrenamiento y los datos de testeo debían ser de 85% (entrenamiento) y 15% (testeo). Si bien sabemos que las proporciones adecuadas son de un 70% o 80% para el entrenamiento, nosotros elegimos un 85% debido a que como tenemos una cantidad de datos reducida, la mayoría de estos análisis se hacen con miles o millones de datos. Es por esto importante que podamos destinar la mayor cantidad de datos posibles a entrenamiento, para así mejorar su aprendizaje y obtener mejores resultados. Sino probablemente no podamos obtener buenos resultados. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a5569e",
   "metadata": {},
   "source": [
    "### Instanciar y entrenar el clasificador \n",
    "En esta parte eligeremos un modelo Naive Bayes y posteriormente lo entrenaremos, siguiendo como etiqueta el atributo de rango de precios (price_range). Para nuestra decisión creamos diversos gráficos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed40ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.displot(data=df, x=\"price_range\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6297d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df, x=\"n_cores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d6115",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df, x=\"fc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9459dabb",
   "metadata": {},
   "source": [
    "Tras analizar estos tres gráficos con tres características al azar, nos damos cuenta que no siguen una distribución gaussiana, por lo que resultaría equivocado usar el metodo de Naive Bayes gaussiano.\n",
    "<br>\n",
    "Finalmente nos decidimos por Naive Bayes multinomial ya que esta técnica nos parece la más apropiada, ya que es frecuentemente utilizada en tareas de clasificación de documentos, por lo que asumimos que sería una buena idea para poder clasificar otras cosas mas allá que solo documentos. Además, también descartamos el Naive Bayes Bernoulli ya que esta orientado a datos tipo binarios (si o no), cosa que no calza con la mayoría de nuestras características. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c787a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult = MultinomialNB(alpha=1, fit_prior=False) #Se crea el objeto mult de clase MultinomialNB con los\n",
    "                                               #hiperparámetros alpha = 1 y fit_prior = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69146c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult.fit(x_train, y_train) #Se entrena con los datos, mediante el modelo MultinomialNB de scikit-learn, gracias al comando 'fit'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3cc42b",
   "metadata": {},
   "source": [
    "Almacenamos en la variable 'mult' un objeto de la libreria sklearn el cual tiene las herramientas del modelo de clasificación escogido. <br> A esta variable le aplicamos la función fit para que entrene los datos. Estos los creamos anteriormente como 'x_train' e 'y_train'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd9f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mult.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c99a350",
   "metadata": {},
   "source": [
    "Ahora se predicen los datos, usamos la función predict, que entregando la matriz de atributos de testeo, nos da la predicción del calificador. Esto lo almacenamos en 'y_pred'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85909b39",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### Cálculo del rendimiento del calificador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb3791",
   "metadata": {},
   "source": [
    "- Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5e2e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy : %0.3f' % (accuracy_score(y_test,y_pred,normalize=True)*100),'%')\n",
    "#Se usa el comando 'accuracy_score' de la librería de Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bbc7d1",
   "metadata": {},
   "source": [
    "Aquí, \"'Accuracy: %0.3f' %\" va a hacer que se imprima la palabra Accuracy, en conjunto con el porcentaje de precisión de las predicciones. La parte de %0.3f limita la cantidad de decimales que se van a mostrar (solo mostrará los primeros 3 decimales). Después, se escribe la función \"accuracy_score\", parte de la librería de Scikit Learn, la cual nos entrega el porcentaje de precisión de las predicciones (en base al array predecido y el array con las respuestas correctas)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd2439c",
   "metadata": {},
   "source": [
    "- precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23155057",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision : %0.3f' % (precision_score(y_test, y_pred, average='macro')*100),'%')\n",
    "#Se usa el comando 'precision_score' de la librería de Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1093cff7",
   "metadata": {},
   "source": [
    "Tras mirar la documentación encontramos la función 'precision_score', la cual entregando el array predecido y el array con respuestas correctas nos entrega la precisión que hubo. Esto lo que hace es calcular las métricas para cada etiqueta y encuentra su media no ponderada. Esto no tiene en cuenta el equilibrio de las etiquetas, pero al tener los datos normalizados es efectivo usarlo. Esto gracias al agregar 'average=macro' entregando la precisión a cada etiqueta y posteriormente calcula la media.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b62a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision por cada clase en porcentaje:',(precision_score(y_test, y_pred, average=None)*100))\n",
    "#Se usa el comando 'precision_score' de la librería de Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc16981",
   "metadata": {},
   "source": [
    "Aquí podemos ver la precisión segun cada clase, obteniendo resultados muy diferentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381190dd",
   "metadata": {},
   "source": [
    ">Nos guiamos bajo la documentación: <br>https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e9d373",
   "metadata": {},
   "source": [
    "- recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5eca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Recall : %0.3f' % (recall_score(y_test, y_pred, average='macro')*100),'%')\n",
    "#Se usa el comando 'recall_score' de la librería de Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34a8b6c",
   "metadata": {},
   "source": [
    "Recall se encarga se sacar la relación (división) entre entre números 'true positives' y los 'false negative'. Se le entrega el array predecido y el array con respuestas correctas. Al ser una división el mejor valor es 1 y el peor 0. Es la capacidad del clasificador de encontrar las muestras positivas. Finalmente, retorna el promedio ponderado de cada clase. Aquí aplicamos el average 'macro'  ya que calcula la métrica para cada etiqueta y encuentra su promedio ponderado (el número de instancias que efectivamente fueron verdaderas). Esto no altera el desequilibrio entre etiquetas al tener los datos normalizados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f0a0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Recall por cada clase en porcentaje:',(recall_score(y_test, y_pred, average=None)*100))\n",
    "#Se usa el comando 'recall_score' de la librería de Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ae258b",
   "metadata": {},
   "source": [
    "Aquí podemos ver el recall según cada clase, obteniendo resultados muy diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a6828",
   "metadata": {},
   "source": [
    "> Nos guiamos bajo la documentación:<br> https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7893e7f",
   "metadata": {},
   "source": [
    "- f-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae902b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('f-1 score : %0.3f' % (f1_score(y_test, y_pred, average='macro')*100),'%')\n",
    "#Se usa el comando 'f1_score' de la librería de Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee11307c",
   "metadata": {},
   "source": [
    "Se calcula la puntuación f, esta métrica es el promedio ponderado de la precisión y del recall, su mejor valor es 1 y el peor es 0, esto se calcula como: f=2*(precisión*recall)/(precisión+recall). Se le entrega el array predecido y el array con respuestas correctas  Lo calculamos nuevamente con average macro ya que saca el promedio de todos, y no es necesario procuparse de las distancias entre los datos al normalizar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('f-1 score por cada clase en porcentaje:',(f1_score(y_test, y_pred, average=None)*100))\n",
    "#Se usa el comando 'f1_score' de la librería de Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f391d01",
   "metadata": {},
   "source": [
    "Aquí podemos ver el f-1 score segun cada clase, obteniendo resultados muy diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e21001",
   "metadata": {},
   "source": [
    ">Nos guiamos bajo la documentación:<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aeccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz = confusion_matrix(y_test, y_pred) \n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "#Gracias a la librería de sklearn.metrics usamos el comando 'confusion_matrix' que le entregamos el real y el vector entrenado,\n",
    "#obteniendo la matriz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1a0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros_precio = ['0','1','2','3']\n",
    "plot_confusion_matrix(mult, x_test, y_test,\n",
    "                      display_labels=parametros_precio,\n",
    "                      cmap=plt.cm.Reds,\n",
    "                      normalize='true')\n",
    "#Se puede visualizar de mejor manera aplicando el comando plot_confusion_matrix\n",
    "#le agregamos el algoritmo entrenado, la matriz de testeo,el vector de label\n",
    "# y el nombre de los parámetros escogidos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eab495",
   "metadata": {},
   "source": [
    "La matriz de confusión nos dice como se distribuyen los labels verdaderos con los que predecimos mediante el entrenamiento. Podemos observar que para predecir los que tienen un rango de precios 0, es mas efectiva la predicción que los que tienen un rango de precios 2. Además, tenemos que para los rango de precios 1 y 3 tienen un mediano acierto. <br>\n",
    "Si bien el accuracy no es tan bueno, podemos ver que si quiero predecir los celulares que estan en el rango de precios 0, esto será mucho más efectivo. Mientras que los que están en el rango de precios 2, tendrá mayores posibilidades de fallará.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3252afd0",
   "metadata": {},
   "source": [
    "##### Hiperparámetros usados para el calificador\n",
    "- Tras ver la documentación de scikitlearn, nos damos cuenta que este modelo clasificador cuenta con 2 hiperparámetros: alpha, fit_prior.\n",
    "- Para el hiperparámetro 'alpha' que tiene la función de suavizar los datos categóricos, no se obtuvo grandes cambios al variar el parámetro ya que variaba el accuracy un par de porcentajes pero bajaba la precisión, por lo mantenemos el predeterminado (1). <br>\n",
    "- Luego para fit_prior vemos que tiene la utilidad de que aprenda las probabilidades previas de la clase, sin embargo, el no realizarlo previamente mejoró la precisión y el accuracy, por lo que no lo aplicaremos (False). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fc70f6",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### Instanciar y entrenar el regresor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db790ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_1 = DecisionTreeRegressor(criterion = 'mae', max_depth=None, min_samples_split = 10, max_features = 'sqrt')\n",
    "#Se crea un objeto de clase DecisionTreeRegresor con los hiperparámetros\n",
    "#criterion = 'mae', max_depth = None, min_samples_split = 10 y max_features = 'sqrt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9154a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_1.fit(X_train, Y_train) #Se entrena el regresor con los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339670f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = regr_1.predict(X_test) #Se realiza una predicción con el regresor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec743316",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Puntaje R^2 para el regresor: ',regr_1.score(X_test, Y_test)) #Se mide un puntaje basado en error para calificar la predicción\n",
    "#Estos scores corresponden a error R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55030e2e",
   "metadata": {},
   "source": [
    "##### Hiperparámetros usados para el regresor\n",
    "- Se cambió el splitter a random. No hizo ninguna diferencia\n",
    "- Se probó usar max_depth 70 y 90. Esto tuvo poca diferencia. Despues se prueba usar max_depth = 30 y el error aumenta, por lo que nos quedaremos con 70 por el momento, ya que al parecer cuando se disminuye el max_depth, genera error.\n",
    "- Al usar min_samples_split = 10 (por defecto es 2), el error disminuye considerablemente. Esto significa que la cantidad de muestras requeridas para dividir un nodo interno es mayor.\n",
    "- Al usar max_features = 'sqrt', el error vuelve a disminuir. Este parámetro controla la cantidad de caracteristicas que se consideran al momento de buscar el mejor split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13659b8d",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### Visualizar la importancia de las features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6055c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat=regr_1.feature_importances_\n",
    "#con el comando feature_importances_ que me entrega las cosas importantes de las features, la almacenamos en feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad46e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat #podemos ver el array obtenido con el comando anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96558252",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'Features values': feat, \"Features\": ['battery_power', 'blue', 'clock_speed','dual_sim','fc', 'four_g','m_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g', 'touch_screen', 'wifi', 'price_range']}\n",
    "#Se crea un DataFrame usando la información almacenada en el array, con el nombre de su característica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ec2b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.DataFrame (data,columns = ['Features values','Features'])\n",
    "#En estos dos últimos comandos creamos un data set en que en las columnas van los valores de las features con su respectivo nombre\n",
    "#creamos un data, en el cual ponemos el nombre de las columnas y su respectiva información"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd43e44",
   "metadata": {},
   "source": [
    ">Información obtenida de: https://datatofish.com/create-pandas-dataframe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de78cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf #aquí podemos ver el resultado del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ed377",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11,11))\n",
    "feat_ = sns.barplot(x='Features', y='Features values', data = fdf)\n",
    "for item in feat_.get_xticklabels():\n",
    "    item.set_rotation(45)\n",
    "plt.xlabel('Importancia de las features')\n",
    "#Se crea un gráfico usando los datos del DataFrame recién creado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac8a4ca",
   "metadata": {},
   "source": [
    "Finalmente creamos un gráfico en que se visualizan de correcta manera cada característica con su respectiva importancia, nos podemos dar cuenta en seguida que las que tenemos menos importancia son en las features que tienen respuestas binarias (yes or no) como: wifi, 3G, 4G, bluetooth, dual_sim y las con rangos pequeños como price_range (solo puede ser 0-1-2-3). Luego podemos ver que las otras características tienen mucha influencia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258f6878",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Parte 3: Informe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f595de",
   "metadata": {},
   "source": [
    "### 1. ¿Cómo resolvieron el tema de los valores nulos? Justifique. (0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eff1b3e",
   "metadata": {},
   "source": [
    "Para resolver el problema de los valores nulos, tomamos la decisión de eliminar toda fila del dataset que tuviera valores nulos (NaN). Esto lo hicimos debido a que todo dispositivo que tiene \"NaN\" en alguno de sus datos, es un teléfono que tiene información incompleta. Nosotros creemos que asignar valores a los NaN es una forma de alterar la información, lo que puede resultar en predicciones menos precisas, o que el clasificador y el regresor no logren aprender patrones de la mejor manera.<br>\n",
    "Por ejemplo, al asignar valores NaN como 0, en caracteristicas como la RAM, no tiene sentido que un teléfono se le asigne ese valor, solo por el hecho de que no estaba registrado originalmente. Asignarle valor 0 a la RAM es asignarle información falsa lo cual puede hacer daño al proceso de aprendizaje del clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf30a28",
   "metadata": {},
   "source": [
    "### 2. ¿Qué normalizaste, filas o columnas? ¿Por qué? ¿Para qué sirve normalizar los datos? ¿Qué tipo de normalización usaste y por qué? Justifique. (0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d02c4e1",
   "metadata": {},
   "source": [
    "Normalizamos las columnas de la matriz de atributos, debido a que los rangos de cada atributo cambian entre si. Normalizar sirve para poder distribuir los datos de una manera más equitativa, y tener en base a un mismo estándar las proporciones de distancias entre los datos de una misma característica. Por ejemplo, en el dataset, tenemos valores como 'n_cores', que va de 1 a 8, y tenemos valores como 'ram', que van entre 1000 y 3000 aprox., sin embargo, la variación en 'n_cores' de una unidad tiene mayores efectos que la variación de 'ram' en una unidad, por lo que debemos normalizar para hacer que esta escala sea igual entre características. Nosotros elegimos la normalización MinMax, debido a que esta es capaz de mantener las proporciones numéricas de los datos y a la vez, generar una escala común para todas las columnas, con valores que van desde 0 a 1, lo cual creemos que funcionará de forma optima para el entrenamiento del clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c0dd63",
   "metadata": {},
   "source": [
    "### 3. ¿Qué gráficos utilizaste para caracterizar los datos?¿Por qué? ¿Qué observaste de los datos, encontraste alguna característica particular? Justifique. (0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821551c7",
   "metadata": {},
   "source": [
    "Utilizamos una gran variedad de gráficos, entre los que se encuentran swarmplot, boxplot, relplot y catplot. Usamos distintos gráficos con el fin de poder visualizar de distintas maneras las distintas características de nuestro dataset según los atributos a medir. Dentro de lo observado, podemos apreciar claramente que la gran mayoría de las características no tienen relación entre sí. Esto podría ser algo muy positivo a la hora de clasificarlo mediante el modelo Naive Bayes, ya que el modelo asume que todas las características deben ser independientes entre si. Aún así, no cumple 100% la independencia, ya que algunas características se relacionan, como por ejemplo el rango de precio y la cantidad de RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b985320",
   "metadata": {},
   "source": [
    "### 4. ¿Por qué se separan los datos en set de entrenamiento y set de pruebas? ¿Qué proporción de los datos utilizaste para cada uno y por qué? Justifique. (0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60559b76",
   "metadata": {},
   "source": [
    "Los datos de entrenamiento y pruebas se deben separar debido a que, para poder comprobar la habilidad de poder predecir, es necesario que entreguemos datos que no se hayan visto antes. Si no separamos los datos de prueba y entrenamiento, no tenemos como saber si nuestro clasificador esta siendo capaz de poder predecir cosas en base a patrones u observaciones de los datos, en lugar de simplemente saber la respuesta porque es algo que ya vió. Debido a esto, es necesario destinar parte de los datos a probar la efecitividad del entrenamiento, y que estos datos de testeo no pueden ser iguales a los de entrenamiento. Nosotros elegimos la proporción 85% / 15% (entrenamiento / testeo). Si bien sabemos que una proporción más ideal sería 70% / 30%, nosotros elegimos la nuestra debido a que como tenemos una cantidad de datos reducida, considerando que la mayoría de analisis de este tipo se hacen con miles o millones de datos. Consideramos que lo mejor es destinar la mayor cantidad de datos posible al entrenamiento para que sea efectivo y obtener mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07d8168",
   "metadata": {},
   "source": [
    "### 5. ¿Qué hiper-parámetros modificaste para probar tu clasificador? ¿Y el regresor? ¿Cuáles combinaciones de parámetros te dieron mejores resultados y por qué crees que es así? Justifique. (0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e5a4d9",
   "metadata": {},
   "source": [
    "Para el clasificador se usaron dos hiperparametros: alpha y fit_prior. La combinación que entregó mejores resultados fue el alpha predeterminado (1) y no usar fit_prior (fit_prior = False). Creemos que esto entregó mejores resultados ya que, aunque fit_prior tenía la utilidad de aprender las características previas de la clase, creemos que esto no fue algo efectivo, debido a que los datos no tienen la posibilidad de ver más allá, haciendo inferencias o ver una variable latente, por lo que es mejor simplemente entrenarlos sin una inferencia previa.<br>\n",
    "\n",
    "Para el regresor se usaron 4 hiperparámetros: criterion, max_depth, min_samples_split y max_features. La combinación de hiperparámetros que funcionó mejor fue criterion = 'mae', max_depth en el default de sklearn, min_samples_split = 10 y max_features = 'sqrt'. Creemos que esto entregó mejores resultados debido a que al momento de crear ramas nuevas (min_samples_split), se necesitan más muestras de lo que normalmente se necesita (con ajustes default), además de que no colocamos limites para la profundidad del arbol (max_depth).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4c392c",
   "metadata": {},
   "source": [
    "### 6. Para el clasificador, explica la diferencia entre las métricas del set de pruebas para cada clase, ¿Qué nos dice de la calidad del clasificador por cada clase? ¿Hay alguna clase que tenga un mejor resultado en la clasificación?. Justifique. (0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4845fd6",
   "metadata": {},
   "source": [
    "El clasificador tuvo diferencia en los valores de las métricas obtenidos en cada clase. En el \"Precision\", en el rango de precio 0 siempre tuvo el mejor valor, seguido del rango de precio 3, ocurriendo lo mismo en el \"Recall\" y en el \"f-1 score\". Esto nos dice que el entrenamiento funcionó mejor para algunas clases antes que otras, teniendo un mayor porcentaje en todas las métricas. Esto lo podemos evidenciar al analizar la matriz de confusión, la cual nos hace ver gráficamente las clases con un mejor resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76c09b2",
   "metadata": {},
   "source": [
    "### 7. Para el regresor, ¿Qué nos dice el error sobre la calidad de la regresión? Justifique. (0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a25100",
   "metadata": {},
   "source": [
    "El error, en nuestro caso, se mide con puntaje $R^2$, en donde el mejor puntaje posible es el 1. Esto significa que cuanto más cerca se esté del 1, significa que la calidad de la regresión es mayor. El puntaje $R^2$ puede ser negativo, debido a que no hay un limite de que tan malo puede ser el modelo de regresión. En nuestro analisis, el error varió entre -1,1 y -0,5. Esto, dentro de todo, es un error prudente, ya que los valores de este puntaje van desde el $-\\infty$ hasta el 1. Si bien no fue una regresión perfecta, se entiende el error que tuvimos, debido a la poca cantidad de datos y el hecho de que este set de datos tuviera mucho ruido, fallando así en las predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d6eda",
   "metadata": {},
   "source": [
    "### 8. ¿Qué observaste en la importancia de las features en el Decision Tree Regressor? Acorde al contexto del set de datos ¿parece razonable la importancia de las features encontradas para realizar la regresión? Justifique. (0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0439ed9d",
   "metadata": {},
   "source": [
    "En el Decision Tree Regresor, podemos ver como las distintas features tienen distintos niveles de importancia. Las diferencias en la importancia de cada feature puede llegar a ser extremadamente distintas entre si (Vease el gráfico más arriba, en la sección \"Visualizar la importancia de las features\"). Según el Decision Tree Regressor, las features que son binarias (si o no) son las que el regresor considera menos importantes, por lo cual no fueron features relevantes al momento de realizar el entrenamiento y poder estimar. Esto parece razonable, ya que las respuestas de \"si\" o \"no\" eran independientes a la memoria interna, lo que era muy dificil para la regresión estimar o recopilar información a partir de estas, mientras que las columnas que tenían mayor importancia tenían distintos valores, pudiendo así, ser un aporte para el regresor. En resumen, podemos notar que se sigue un patron en la influencia de las features en el Decision Tree Regresor. Estos patrones se notan claramente en que sean respuestas de \"si\" o \"no\", del cual podemos concluir que al hacer este tipo de regresiones, los datos que no son binarios son los que más aportan información para realizar un mejor entrenamiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
